{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ee\n",
    "import io\n",
    "from google.api_core import exceptions, retry\n",
    "import google.auth\n",
    "from models import *\n",
    "\n",
    "PROJECT = \"pc530-fao-fra-rss\"  # change to your cloud project name\n",
    "# ee.Initialize(project=PROJECT)\n",
    "\n",
    "## INIT WITH HIGH VOLUME ENDPOINT\n",
    "credentials, _ = google.auth.default()\n",
    "ee.Initialize(\n",
    "credentials,\n",
    "project=PROJECT,\n",
    "opt_url=\"https://earthengine-highvolume.googleapis.com\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ee_img(coords):\n",
    "    \"\"\"retrieve s2 image composite from ee at given coordinates. coords is a tuple of (lon, lat) in degrees.\"\"\"\n",
    "    ## MAKE S2 COMPOSITE IN HEXAGONS ##########################################\n",
    "    # Using Cloud Score + for cloud/cloud-shadow masking\n",
    "    # Harmonized Sentinel-2 Level 2A collection.\n",
    "    s2 = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "\n",
    "    # Cloud Score+ image collection. Note Cloud Score+ is produced from Sentinel-2\n",
    "    # Level 1C data and can be applied to either L1C or L2A collections.\n",
    "    csPlus = ee.ImageCollection(\"GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED\")\n",
    "\n",
    "    # Use 'cs' or 'cs_cdf', depending on your use case; see docs for guidance.\n",
    "    QA_BAND = \"cs_cdf\"\n",
    "\n",
    "    # The threshold for masking; values between 0.50 and 0.65 generally work well.\n",
    "    # Higher values will remove thin clouds, haze & cirrus shadows.\n",
    "    CLEAR_THRESHOLD = 0.50\n",
    "\n",
    "    # Make a clear median composite.\n",
    "    sampleImage = (\n",
    "        s2.filterDate(\"2023-01-01\", \"2023-12-31\")\n",
    "        .filterBounds(ee.Geometry.Point(coords[0], coords[1]).buffer(64*10)) # only images touching 64 pixel centroid buffer\n",
    "        .linkCollection(csPlus, [QA_BAND])\n",
    "        .map(lambda img: img.updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD)))\n",
    "        .median()\n",
    "        .select([\"B4\", \"B3\", \"B2\", \"B8\"], [\"R\", \"G\", \"B\", \"N\"])\n",
    "    )\n",
    "    return sampleImage\n",
    "\n",
    "@retry.Retry()\n",
    "def get_patch(coords, image, format=\"NPY\"):\n",
    "    \"\"\"Uses ee.data.ComputePixels() to get a 32x32 patch centered on the coordinates, as a numpy array.\"\"\"\n",
    "    \n",
    "    # Output resolution in meters.\n",
    "    SCALE = 10\n",
    "\n",
    "    # Pre-compute a geographic coordinate system.\n",
    "    proj = ee.Projection(\"EPSG:4326\").atScale(SCALE).getInfo()\n",
    "\n",
    "    # Get scales in degrees out of the transform.\n",
    "    SCALE_X = proj[\"transform\"][0]\n",
    "    SCALE_Y = -proj[\"transform\"][4]\n",
    "\n",
    "    # Patch size in pixels.\n",
    "    PATCH_SIZE = 32\n",
    "\n",
    "    # Offset to the upper left corner.\n",
    "    OFFSET_X = -SCALE_X * PATCH_SIZE / 2\n",
    "    OFFSET_Y = -SCALE_Y * PATCH_SIZE / 2\n",
    "    \n",
    "    REQUEST = {\n",
    "        \"fileFormat\": \"NPY\",\n",
    "        \"grid\": {\n",
    "            \"dimensions\": {\"width\": PATCH_SIZE, \"height\": PATCH_SIZE},\n",
    "            \"affineTransform\": {\n",
    "                \"scaleX\": SCALE_X,\n",
    "                \"shearX\": 0,\n",
    "                \"shearY\": 0,\n",
    "                \"scaleY\": SCALE_Y,\n",
    "            },\n",
    "            \"crsCode\": proj[\"crs\"],\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    request = dict(REQUEST)\n",
    "    request[\"fileFormat\"] = format\n",
    "    request[\"expression\"] = image\n",
    "    request[\"grid\"][\"affineTransform\"][\"translateX\"] = coords[0] + OFFSET_X\n",
    "    request[\"grid\"][\"affineTransform\"][\"translateY\"] = coords[1] + OFFSET_Y\n",
    "    return np.load(io.BytesIO(ee.data.computePixels(request)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102.56, -1.18]\n"
     ]
    }
   ],
   "source": [
    "id, latlon = 1233804841, [102.56,-1.18]#[102.19,-1.54]#[-60.25204,3.86655]#[-172.3490007781034,-13.523357265222518] #[-257.82, -1.54]#\n",
    "print(latlon)\n",
    "image = get_ee_img(latlon)\n",
    "patch = get_patch(latlon, image)\n",
    "# print(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa44f35c37dd4c38bb83444edb945a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-1.18, 102.56000000000002], controls=(WidgetControl(options=['position', 'transparent_bg'], widgetâ€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geemap\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(image, {\"bands\": [\"R\", \"G\", \"B\"], \"min\": 0, \"max\": 2000}, \"S2\")\n",
    "Map.addLayer(ee.Geometry.Point(latlon), {\"color\": \"red\"}, \"Centroid\")\n",
    "Map.centerObject(ee.Geometry.Point(latlon), 18)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.lib.recfunctions import structured_to_unstructured\n",
    "unstruct = structured_to_unstructured(patch)\n",
    "# print(unstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rescaled = unstruct.astype(np.float64) / 10000\n",
    "# print(rescaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transposed = np.transpose(rescaled, (1, 2, 0))\n",
    "# print(transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how to get numpy array of 4 bands into correct shape for model prediction\n",
    "reshaped = np.reshape(transposed, (1, 32, 32, 4))\n",
    "# print(reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found: resnet\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 4)]       0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 1, 1, 2048)        23590848  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,115,649\n",
      "Trainable params: 0\n",
      "Non-trainable params: 24,115,649\n",
      "_________________________________________________________________\n",
      "None\n",
      "tf.Tensor([[0.01512885]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 5-epoch resnet trained on full tfrecord set (tfrecords/all)\n",
    "model_name = \"resnet\"\n",
    "optimizer = \"adam\"\n",
    "loss_function = \"binary_crossentropy\"\n",
    "checkpoint = \"C:\\\\fao-models\\\\saved_models\\\\resnet-epochs5-batch64-lr001-seed5-lrdecay5-tfrecords-all\\\\best_model.h5\"\n",
    "# load several model versions into memory..\n",
    "model = get_model(model_name, optimizer=optimizer, loss_fn=loss_function)\n",
    "model.load_weights(checkpoint)\n",
    "freeze(model)\n",
    "\n",
    "# print(model.summary())\n",
    "prediction = model(reshaped)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found: resnet\n",
      "tf.Tensor([[0.00071617]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 30-epoch resnet with 86% binary accuracy\n",
    "model_name = \"resnet\"\n",
    "optimizer = \"adam\"\n",
    "loss_function = \"binary_crossentropy\"\n",
    "checkpoint = \"C:\\\\fao-models\\\\saved_models\\\\resnet-epochs30-batch64-lr001\\\\best_model.h5\"\n",
    "\n",
    "# load several model versions into memory..\n",
    "model = get_model(model_name, optimizer=optimizer, loss_fn=loss_function)\n",
    "model.load_weights(checkpoint)\n",
    "freeze(model)\n",
    "# print(model.summary())\n",
    "# apply sigmoid fn to from logits to prob\n",
    "prediction = model(reshaped)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found: mobilenet_v3small\n",
      "tf.Tensor([[0.00288773]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 10 epoch mobilenetv3small with 82% acc\n",
    "model_name = \"mobilenet_v3small\"\n",
    "optimizer = \"adam\"\n",
    "loss_function = \"binary_crossentropy\"\n",
    "checkpoint = \"C:\\\\fao-models\\\\saved_models\\\\mobilenetv3small-epochs10-batch32-lr01\\\\best_model.h5\"\n",
    "\n",
    "# load several model versions into memory..\n",
    "model = get_model(model_name, optimizer=optimizer, loss_fn=loss_function)\n",
    "model.load_weights(checkpoint)\n",
    "freeze(model)\n",
    "\n",
    "# print(model.summary())\n",
    "prediction = model(reshaped)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found: resnet\n",
      "tf.Tensor([[0.03912623]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 15 epoch resnet with 98% binary accuracy \n",
    "model_name = \"resnet\"\n",
    "optimizer = \"adam\"\n",
    "loss_function = \"binary_crossentropy\"\n",
    "checkpoint = \"C:\\\\fao-models\\\\saved_models\\\\resnet-epochs5-batch64-lr001-seed5-lrdecay5\\\\best_model.h5\"\n",
    "# load several model versions into memory..\n",
    "model = get_model(model_name, optimizer=optimizer, loss_fn=loss_function)\n",
    "model.load_weights(checkpoint)\n",
    "freeze(model)\n",
    "# print(model.summary())\n",
    "prediction = model(reshaped)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found: mobilenet_v3small\n",
      "tf.Tensor([[0.9805746]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# very early model.. didn't even save its training params\n",
    "model_name = \"mobilenet_v3small\"\n",
    "optimizer = \"adam\"\n",
    "loss_function = \"binary_crossentropy\"\n",
    "\n",
    "checkpoint = \"C:\\\\fao-models\\\\saved_models\\\\mobilenet_v3small_batch255\\\\best_model.h5\"\n",
    "\n",
    "# load several model versions into memory..\n",
    "model = get_model(model_name, optimizer=optimizer, loss_fn=loss_function)\n",
    "model.load_weights(checkpoint)\n",
    "freeze(model)\n",
    "# print(model.summary())\n",
    "prediction = model(reshaped)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
