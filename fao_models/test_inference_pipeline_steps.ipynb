{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ee\n",
    "import io\n",
    "from google.api_core import exceptions, retry\n",
    "import google.auth\n",
    "from models import *\n",
    "\n",
    "PROJECT = \"pc530-fao-fra-rss\"  # change to your cloud project name\n",
    "# ee.Initialize(project=PROJECT)\n",
    "\n",
    "## INIT WITH HIGH VOLUME ENDPOINT\n",
    "credentials, _ = google.auth.default()\n",
    "ee.Initialize(\n",
    "credentials,\n",
    "project=PROJECT,\n",
    "opt_url=\"https://earthengine-highvolume.googleapis.com\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ee_img(coords):\n",
    "    \"\"\"retrieve s2 image composite from ee at given coordinates. coords is a tuple of (lon, lat) in degrees.\"\"\"\n",
    "    ## MAKE S2 COMPOSITE IN HEXAGONS ##########################################\n",
    "    # Using Cloud Score + for cloud/cloud-shadow masking\n",
    "    # Harmonized Sentinel-2 Level 2A collection.\n",
    "    s2 = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "\n",
    "    # Cloud Score+ image collection. Note Cloud Score+ is produced from Sentinel-2\n",
    "    # Level 1C data and can be applied to either L1C or L2A collections.\n",
    "    csPlus = ee.ImageCollection(\"GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED\")\n",
    "\n",
    "    # Use 'cs' or 'cs_cdf', depending on your use case; see docs for guidance.\n",
    "    QA_BAND = \"cs_cdf\"\n",
    "\n",
    "    # The threshold for masking; values between 0.50 and 0.65 generally work well.\n",
    "    # Higher values will remove thin clouds, haze & cirrus shadows.\n",
    "    CLEAR_THRESHOLD = 0.50\n",
    "\n",
    "    # Make a clear median composite.\n",
    "    sampleImage = (\n",
    "        s2.filterDate(\"2023-01-01\", \"2023-12-31\")\n",
    "        .filterBounds(ee.Geometry.Point(coords[0], coords[1]).buffer(64*10)) # only images touching 64 pixel centroid buffer\n",
    "        .linkCollection(csPlus, [QA_BAND])\n",
    "        .map(lambda img: img.updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD)))\n",
    "        .median()\n",
    "        .select([\"B4\", \"B3\", \"B2\", \"B8\"], [\"R\", \"G\", \"B\", \"N\"])\n",
    "    )\n",
    "    return sampleImage\n",
    "\n",
    "@retry.Retry()\n",
    "def get_patch(coords, image, format=\"NPY\"):\n",
    "    \"\"\"Uses ee.data.ComputePixels() to get a 32x32 patch centered on the coordinates, as a numpy array.\"\"\"\n",
    "    \n",
    "    # Output resolution in meters.\n",
    "    SCALE = 10\n",
    "\n",
    "    # Pre-compute a geographic coordinate system.\n",
    "    proj = ee.Projection(\"EPSG:4326\").atScale(SCALE).getInfo()\n",
    "\n",
    "    # Get scales in degrees out of the transform.\n",
    "    SCALE_X = proj[\"transform\"][0]\n",
    "    SCALE_Y = -proj[\"transform\"][4]\n",
    "\n",
    "    # Patch size in pixels.\n",
    "    PATCH_SIZE = 32\n",
    "\n",
    "    # Offset to the upper left corner.\n",
    "    OFFSET_X = -SCALE_X * PATCH_SIZE / 2\n",
    "    OFFSET_Y = -SCALE_Y * PATCH_SIZE / 2\n",
    "    \n",
    "    REQUEST = {\n",
    "        \"fileFormat\": \"NPY\",\n",
    "        \"grid\": {\n",
    "            \"dimensions\": {\"width\": PATCH_SIZE, \"height\": PATCH_SIZE},\n",
    "            \"affineTransform\": {\n",
    "                \"scaleX\": SCALE_X,\n",
    "                \"shearX\": 0,\n",
    "                \"shearY\": 0,\n",
    "                \"scaleY\": SCALE_Y,\n",
    "            },\n",
    "            \"crsCode\": proj[\"crs\"],\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    request = dict(REQUEST)\n",
    "    request[\"fileFormat\"] = format\n",
    "    request[\"expression\"] = image\n",
    "    request[\"grid\"][\"affineTransform\"][\"translateX\"] = coords[0] + OFFSET_X\n",
    "    request[\"grid\"][\"affineTransform\"][\"translateY\"] = coords[1] + OFFSET_Y\n",
    "    return np.load(io.BytesIO(ee.data.computePixels(request)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "id, latlon = 1233804841, [-172.3490007781034,-13.523357265222518]#[102.41,-1.19]#[102.4, -1.19]#[102.56,-1.18]#[102.19,-1.54]#[-60.25204,3.86655]#[-172.3490007781034,-13.523357265222518] #[-257.82, -1.54]#\n",
    "image = get_ee_img(latlon)\n",
    "patch = get_patch(latlon, image)\n",
    "print(patch.shape) # (32,32)\n",
    "# print(patch) # needs to be of shape (4,32,32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ddf2f08d57411dbc34562bd819e913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-13.523357265222518, -172.3490007781034], controls=(WidgetControl(options=['position', 'transparenâ€¦"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geemap\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(image, {\"bands\": [\"R\", \"G\", \"B\"], \"min\": 0, \"max\": 2000}, \"S2\")\n",
    "Map.addLayer(ee.Geometry.Point(latlon), {\"color\": \"red\"}, \"Centroid\")\n",
    "Map.centerObject(ee.Geometry.Point(latlon), 18)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 4)\n",
      "Model found: resnet\n",
      "(0.95, 'Forest')\n"
     ]
    }
   ],
   "source": [
    "def to_tensor(patch):\n",
    "    \"\"\"\n",
    "    Converts a numpy array to a tf tensor\n",
    "    \"\"\"\n",
    "    from numpy.lib.recfunctions import structured_to_unstructured\n",
    "    \n",
    "    unstruct = structured_to_unstructured(patch) # converts to CHW shape\n",
    "    rescaled = unstruct.astype(np.float64) / 10000 # scale it \n",
    "    reshaped = np.reshape(rescaled, (1, 32, 32, 4)) # batch it\n",
    "    return reshaped\n",
    "\n",
    "def make_inference(tensor):\n",
    "    \"\"\"Loads model for inference and returns prediction on the provided tensor\"\"\"\n",
    "    import numpy as np\n",
    "    # 20-epoch resnet trained on full tfrecord set (tfrecords/all)\n",
    "    model_name = \"resnet\"\n",
    "    optimizer = \"adam\"\n",
    "    loss_function = \"binary_crossentropy\"\n",
    "    checkpoint = \"C:\\\\fao-models\\\\saved_models\\\\resnet-epochs20-batch64-lr001-seed5-lrdecay5-tfrecords-all\\\\best_model.h5\"\n",
    "    model = get_model(model_name, optimizer=optimizer, loss_fn=loss_function, training_mode=True)\n",
    "    model.load_weights(checkpoint)\n",
    "    freeze(model)\n",
    "\n",
    "    prob = round(float(model(tensor).numpy()),2)\n",
    "    prediction = \"Forest\" if prob > 0.5 else \"Non-Forest\"\n",
    "    return prob,prediction\n",
    "\n",
    "tensor = to_tensor(patch)\n",
    "print(tensor.shape)\n",
    "out = make_inference(tensor)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
